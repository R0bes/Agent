# ğŸš€ Agent - Modulares Chat-System mit KI-Integration

Ein vollstÃ¤ndiges Chat-System mit modularem Backend, React-Frontend und KI-Agent-Integration. Das System unterstÃ¼tzt sowohl normale als auch Streaming-Chat-Antworten Ã¼ber WebSocket.

## ğŸ—ï¸ Systemarchitektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    WebSocket    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React UI      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Python Server  â”‚
â”‚   (Port 5173)   â”‚                 â”‚   (Port 9797)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   Ollama LLM    â”‚
                                    â”‚  (Port 11434)   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Features

### **Backend (Python)**
- **FastAPI-Server** mit WebSocket-UnterstÃ¼tzung
- **Modulare Task-Engine** mit PrioritÃ¤tswarteschlange
- **KI-Agent-System** (Queen Agent mit Ollama-Integration)
- **Streaming-Responses** Token fÃ¼r Token
- **Event-basierte Architektur** fÃ¼r Skalierbarkeit

### **Frontend (React)**
- **Moderne React 18+ UI** mit TypeScript
- **WebSocket-Integration** fÃ¼r Echtzeit-Kommunikation
- **Streaming-UI** mit live wachsenden Nachrichten
- **Responsive Design** fÃ¼r alle GerÃ¤te
- **Toggle zwischen normalen und Streaming-Modi**

### **KI-Integration**
- **Ollama-Integration** fÃ¼r lokale LLMs
- **Queen Agent** als zentraler Chat-Assistent
- **Streaming-Generierung** fÃ¼r bessere UX
- **Fallback-Mechanismus** bei Streaming-Fehlern

## ğŸš€ Quick Start

### **Voraussetzungen**
- Python 3.10+
- Node.js 18+
- Ollama (lÃ¤uft auf Port 11434)

### **Installation & Start**

```bash
# 1. Repository klonen
git clone <repository-url>
cd Agent

# 2. Backend starten
cd server
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows
pip install -r requirements.txt
python3 main.py

# 3. Frontend starten (neues Terminal)
cd ui
npm install
npm run dev

# 4. Ollama starten (falls nicht lÃ¤uft)
ollama serve
```

### **Zugriff**
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:9797
- **API Docs**: http://localhost:9797/docs
- **Ollama**: http://localhost:11434

## ğŸ“ Projektstruktur

```
Agent/
â”œâ”€â”€ README.md                 # Diese Datei
â”œâ”€â”€ .gitignore               # Git-Ignore-Regeln
â”œâ”€â”€ Makefile                 # Build/Deploy-Automation
â”œâ”€â”€ server/                  # Python Backend
â”‚   â”œâ”€â”€ README.md           # Backend-Dokumentation
â”‚   â”œâ”€â”€ main.py             # Server-Entrypoint
â”‚   â”œâ”€â”€ api.py              # FastAPI + WebSocket
â”‚   â”œâ”€â”€ config.py           # Konfiguration
â”‚   â”œâ”€â”€ core.py             # WebSocket-Manager
â”‚   â”œâ”€â”€ requirements.txt    # Python-Dependencies
â”‚   â”œâ”€â”€ tasks/              # Task-Engine
â”‚   â”‚   â”œâ”€â”€ engine.py       # Task-Verarbeitung
â”‚   â”‚   â”œâ”€â”€ base.py         # Task-Basisklassen
â”‚   â”‚   â””â”€â”€ message_tasks.py # Nachrichten-Tasks
â”‚   â””â”€â”€ agents/             # KI-Agenten
â”‚       â”œâ”€â”€ base_agent.py   # Agent-Basisklassen
â”‚       â”œâ”€â”€ ollama_agent.py # Ollama-Integration
â”‚       â””â”€â”€ queen_agent.py  # Haupt-Chat-Agent
â””â”€â”€ ui/                     # React Frontend
    â”œâ”€â”€ README.md           # Frontend-Dokumentation
    â”œâ”€â”€ package.json        # Node.js-Dependencies
    â”œâ”€â”€ src/                # React-Quellcode
    â”‚   â”œâ”€â”€ components/     # React-Komponenten
    â”‚   â”œâ”€â”€ config/         # Konfiguration
    â”‚   â””â”€â”€ App.tsx         # Haupt-App
    â””â”€â”€ public/             # Statische Assets
```

## ğŸ”§ Entwicklung

### **Backend-Entwicklung**
```bash
cd server
# Auto-Reload aktiviert (Standard)
python3 main.py

# Tests ausfÃ¼hren
python3 -m agents.test_agent
python3 -m agents.test_queen
```

### **Frontend-Entwicklung**
```bash
cd ui
# Development-Server
npm run dev

# Build fÃ¼r Produktion
npm run build

# Tests (falls konfiguriert)
npm test
```

### **Makefile-Targets**
```bash
# Beide Services starten
make up

# Einzeln starten
make server_up
make ui_up

# Beide stoppen
make down

# AufrÃ¤umen
make clean
```

## ğŸ“¡ API-Endpunkte

### **HTTP-Endpunkte**
- `GET /` - API-Ãœbersicht
- `POST /chat` - Normale Chat-Antwort
- `POST /chat/stream` - Streaming-Chat-Antwort

### **WebSocket-Endpunkte**
- `WS /ws/{client_id}` - Chat-Verbindung

### **Nachrichtentypen**
- `message` - Normale Chat-Nachricht
- `stream_request` - Streaming-Chat-Anfrage
- `ping` - Verbindungstest
- `status` - Status-Anfrage

## ğŸ”„ Streaming-Protokoll

### **Streaming-Nachrichten**
1. **`streaming_start`** - Neue Streaming-Session
2. **`streaming_token`** - Einzelne Token (wiederholt)
3. **`streaming_end`** - Streaming beenden

### **Beispiel-Stream**
```json
{"type": "streaming_start", "streamId": "stream_123", "timestamp": "..."}
{"type": "streaming_token", "streamId": "stream_123", "content": "H", "timestamp": "..."}
{"type": "streaming_token", "streamId": "stream_123", "content": "a", "timestamp": "..."}
{"type": "streaming_token", "streamId": "stream_123", "content": "l", "timestamp": "..."}
{"type": "streaming_end", "streamId": "stream_123", "timestamp": "..."}
```

## ğŸ§ª Testing

### **Backend-Tests**
```bash
cd server
# Agent-Tests
python3 -m agents.test_agent
python3 -m agents.test_queen

# Beispiele
python3 -m agents.queen_example
```

### **Frontend-Tests**
```bash
cd ui
npm test
```

## ğŸ” Debugging

### **Backend-Logs**
```bash
cd server
tail -f server.log
```

### **Frontend-DevTools**
- Browser DevTools Ã¶ffnen
- WebSocket-Tab fÃ¼r Nachrichtenverfolgung
- Console fÃ¼r JavaScript-Logs

### **Ollama-Status**
```bash
curl http://localhost:11434/api/tags
```

## ğŸš€ Deployment

### **Produktions-Build**
```bash
# Frontend
cd ui
npm run build

# Backend
cd server
pip install -r requirements.txt
python3 main.py
```

### **Docker (geplant)**
```bash
# Docker-Compose wird implementiert
docker-compose up -d
```

## ğŸ¤ Beitragen

1. **Fork** das Repository
2. **Feature-Branch** erstellen (`git checkout -b feature/amazing-feature`)
3. **Commit** deine Ã„nderungen (`git commit -m 'Add amazing feature'`)
4. **Push** zum Branch (`git push origin feature/amazing-feature`)
5. **Pull Request** erstellen

## ğŸ“ Changelog

### **v1.0.0** - Initial Release
- âœ… Modulares Backend mit FastAPI
- âœ… React-Frontend mit TypeScript
- âœ… WebSocket-Integration
- âœ… Ollama-LLM-Integration
- âœ… Streaming-Responses
- âœ… Task-Engine-Architektur

## ğŸ“„ Lizenz

Dieses Projekt steht unter der MIT-Lizenz. Siehe `LICENSE` fÃ¼r Details.

## ğŸ†˜ Support

- **Issues**: GitHub Issues verwenden
- **Discussions**: GitHub Discussions fÃ¼r Fragen
- **Wiki**: Projekt-Wiki fÃ¼r detaillierte Dokumentation

---

**Entwickelt mit â¤ï¸ fÃ¼r modulare, skalierbare Chat-Systeme**
